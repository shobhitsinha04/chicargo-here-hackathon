{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import json\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import shapely\n",
        "from shapely.ops import substring\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "\n",
        "probe_data = pd.read_csv(\"23608577_probe_data.csv\")\n",
        "\n",
        "full_topology_data = gpd.read_file(r\"23608577_full_topology_data.geojson\")\n",
        "combined_data = gpd.read_file(r\"23608577_combined.geojson\")\n",
        "access_chars_data = gpd.read_file(r\"23608577_access_chars.geojson\")\n",
        "signs_data = gpd.read_file(r\"23608577_signs.geojson\")\n",
        "validations_data = gpd.read_file(r\"23608577_validations.geojson\")"
      ],
      "metadata": {
        "id": "n5zy9dUqq0GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting existence score for each sign\n",
        "\n",
        "def get_existence_score(conf):\n",
        "    if isinstance(conf, str):\n",
        "        try:\n",
        "            conf = json.loads(conf)\n",
        "        except json.JSONDecodeError:\n",
        "            return None\n",
        "    if isinstance(conf, dict) and \"simpleScores\" in conf:\n",
        "        for score_entry in conf[\"simpleScores\"]:\n",
        "            if score_entry.get(\"scoreType\") == \"EXISTENCE\":\n",
        "                return score_entry.get(\"score\")\n",
        "    return None\n",
        "\n",
        "signs_data[\"existenceScore\"] = signs_data[\"confidence\"].apply(get_existence_score)\n",
        "# print(signs_data[\"existenceScore\"])\n",
        "signs_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFFPt4Twq3TW",
        "outputId": "b5473c6e-1156-4a94-ebeb-c64325ba7578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5662, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering for motorway signs\n",
        "\n",
        "motorway_signs = signs_data[signs_data['signType'] == 'MOTORWAY']\n",
        "print(motorway_signs['existenceScore'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ktvlk293rPBU",
        "outputId": "430dd8a2-80f5-4b70-d0ce-5bd6aa407cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5465    1.0\n",
            "5647    1.0\n",
            "Name: existenceScore, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scenario 1\n",
        "\n",
        "for _, vio in validations_data.iterrows():\n",
        "    feature_id = vio.get(\"Feature ID\")\n",
        "\n",
        "    match = motorway_signs[motorway_signs[\"id\"] == feature_id]\n",
        "\n",
        "    if not match.empty:\n",
        "        existence_score = match.iloc[0].get(\"existenceScore\")\n",
        "\n",
        "        if existence_score is not None:\n",
        "            if existence_score > 0.7:\n",
        "                print(f\"Feature ID {feature_id}: existenceScore {existence_score:.2f} > 0.7 ----- CHECKING SCENARIO 2\")\n",
        "            else:\n",
        "                print(f\"Feature ID {feature_id}: existenceScore {existence_score:.2f} <= 0.7 ----- RESOLVED\") # drop this sign from validations dataset - it is not a violation\n",
        "        else:\n",
        "            print(f\"Feature ID {feature_id}: existenceScore is None\")\n",
        "    else:\n",
        "        print(f\"Feature ID {feature_id} not found in motorway_signs\")\n",
        "\n",
        "# validations_filtered = validations_data[validations_data[\"Feature ID\"] == motorway_signs[motorway_signs[\"existenceScore\"] > 0.7]]\n",
        "filtered_motorway_signs = motorway_signs[motorway_signs[\"existenceScore\"] > 0.7]\n",
        "feature_ids = filtered_motorway_signs[\"id\"]\n",
        "validations_filtered = validations_data[validations_data[\"Feature ID\"].isin(feature_ids)]\n",
        "\n",
        "print(validations_filtered.shape)\n",
        "print(validations_filtered['geometry'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz1hDdXusWcL",
        "outputId": "51db2b29-d378-4614-d6aa-456ee40e9acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature ID urn:here::here:signs:1622369126135402107: existenceScore 1.00 > 0.7 ----- CHECKING SCENARIO 2\n",
            "(1, 12)\n",
            "0    POINT (10.0047 53.51555)\n",
            "Name: geometry, dtype: geometry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to calculate tile bounds (latitudes and longitudes)\n",
        "def calculate_tile_bounds(latitude, longitude, tile_size_meters=1000):\n",
        "    # radius of earth in meters\n",
        "    earth_radius = 6378137.0\n",
        "\n",
        "    # convert tile size from meters to degrees\n",
        "    # for latitude, 1 degree is approximately 111,111 meters (varies slightly with latitude)\n",
        "    # for longitude, 1 degree varies with latitude\n",
        "    half_tile_size = tile_size_meters / 2.0\n",
        "\n",
        "    # calculate latitude bounds (north-south)\n",
        "    # 111,111 meters per degree of latitude is a good approximation\n",
        "    lat_meters_per_degree = 111111.0\n",
        "    lat_delta = half_tile_size / lat_meters_per_degree\n",
        "\n",
        "    north_bound = latitude + lat_delta\n",
        "    south_bound = latitude - lat_delta\n",
        "\n",
        "    # calculate longitude bounds (east-west)\n",
        "    # cos(lat) accounts for the convergence of meridians\n",
        "    lon_meters_per_degree = 111111.0 * np.cos(np.radians(latitude))\n",
        "    lon_delta = half_tile_size / lon_meters_per_degree\n",
        "\n",
        "    east_bound = longitude + lon_delta\n",
        "    west_bound = longitude - lon_delta\n",
        "\n",
        "    return {\"north\": north_bound, \"south\": south_bound, \"east\": east_bound, \"west\": west_bound}\n"
      ],
      "metadata": {
        "id": "L5D0gvl2vGtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make geojson output file\n",
        "\n",
        "import json\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import shapely\n",
        "from shapely.ops import substring\n",
        "\n",
        "##########################################################\n",
        "### LOAD FULL TOPOLOGY TILE\n",
        "##########################################################\n",
        "topology_gdf = gpd.read_file(r\"23608577_full_topology_data.geojson\")\n",
        "\n",
        "##########################################################\n",
        "### FILTER TO THE SELECTED PARAMETERIZED ATTRIBUTE\n",
        "##########################################################\n",
        "access_characteristics_gdf = topology_gdf[['id','accessCharacteristics', 'topologyCharacteristics', 'geometry']].copy()\n",
        "\n",
        "##########################################################\n",
        "### NORMALIZE THE COLUMN WITH JSON LOADS\n",
        "##########################################################\n",
        "def convert_data(x):\n",
        "            try:\n",
        "                return json.loads(x)\n",
        "            except:\n",
        "                return {}\n",
        "access_characteristics_gdf['accessCharacteristics'] = access_characteristics_gdf['accessCharacteristics'].apply(convert_data)\n",
        "access_characteristics_gdf['topologyCharacteristics'] = access_characteristics_gdf['topologyCharacteristics'].apply(convert_data)\n",
        "\n",
        "def extract_is_motorway(top_char):\n",
        "    try:\n",
        "        return top_char.get('isMotorway', [{}])[0].get('value', None)\n",
        "    except (TypeError, IndexError, AttributeError):\n",
        "        return None\n",
        "\n",
        "access_characteristics_gdf['isMotorway'] = access_characteristics_gdf['topologyCharacteristics'].apply(extract_is_motorway)\n",
        "\n",
        "##########################################################\n",
        "### EXPLODE DATASET BASED ON THE PARAMETERIZED ATTRIBUTION COLUMN (essentially duplicate some geoms before cutting)\n",
        "##########################################################\n",
        "access_characteristics_gdf = access_characteristics_gdf.explode('accessCharacteristics')\n",
        "access_characteristics_gdf['id'] = access_characteristics_gdf['id']\n",
        "# access_characteristics_gdf['adasTopology'] = access_characteristics_gdf['adasTopology'][]\n",
        "# def extract_endNode_id(adas_topology):\n",
        "#     try:\n",
        "#         return adas_topology['endNodeTraversals'][0]['references'][0]['id']\n",
        "#     except (KeyError, IndexError, TypeError):\n",
        "#         return None\n",
        "\n",
        "# access_characteristics_gdf['id'] = access_characteristics_gdf['adasTopology'].apply(extract_endNode_id)\n",
        "\n",
        "##########################################################\n",
        "### GET START AND END OFFSET\n",
        "##########################################################\n",
        "access_characteristics_gdf['startOffset'] = access_characteristics_gdf['accessCharacteristics'].str['range'].str['startOffset']\n",
        "access_characteristics_gdf['endOffset'] = access_characteristics_gdf['accessCharacteristics'].str['range'].str['endOffset']\n",
        "\n",
        "##########################################################\n",
        "### SPLIT SHAPELY GEOMETRY\n",
        "##########################################################\n",
        "def split_shapely_string(geom_column, start_offset, end_offset):\n",
        "    try:\n",
        "        result = substring(geom_column, start_dist=start_offset, end_dist=end_offset, normalized=True)\n",
        "        result = shapely.transform(result, lambda x: x, include_z=False)\n",
        "    except Exception as e:\n",
        "        result = None\n",
        "        print(\"SKIPPED GEOMETRY SUBSTRING SPLIT\", e)\n",
        "    return result\n",
        "access_characteristics_gdf['geometry'] = access_characteristics_gdf.apply(lambda x: split_shapely_string(x.geometry, x['startOffset'], x['endOffset']), axis=1)\n",
        "\n",
        "##########################################################\n",
        "### JSON NORMALIZE NEW GDF TO SPLIT OUT COLUMNS\n",
        "##########################################################\n",
        "access_characteristics_gdf = pd.json_normalize(data=pd.DataFrame.to_dict(access_characteristics_gdf, orient='records'))\n",
        "access_characteristics_gdf = gpd.GeoDataFrame(data=access_characteristics_gdf, geometry=access_characteristics_gdf['geometry'])\n",
        "\n",
        "access_characteristics_gdf.to_file(\"output577_new.geojson\")"
      ],
      "metadata": {
        "id": "7SK6NTuPHftY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10879f44-8a95-4099-f6da-5fad954cb0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyogrio/geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
            "  write(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make csv file from data which has id pedestrian and start and end and motorway\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "# Load GeoJSON data\n",
        "geojson_path = 'output577_new.geojson'\n",
        "gdf = gpd.read_file(geojson_path)\n",
        "\n",
        "# Extract required fields\n",
        "processed_data = []\n",
        "for _, row in gdf.iterrows():\n",
        "    geometry = row.geometry\n",
        "    properties = row\n",
        "\n",
        "    # Extract numeric ID at the end\n",
        "    id_full = properties.get('id', '')\n",
        "    id_ = id_full.split(':')[-1] if id_full else None\n",
        "\n",
        "    pedestrian = row.get('accessCharacteristics.pedestrian')\n",
        "    # Access pedestrian and topologyCharacteristics values correctly\n",
        "    #access_char = properties.get('accessCharacteristics', {})\n",
        "    motorway = properties.get('isMotorway', {})\n",
        "\n",
        "\n",
        "    # Extract isMotorway safely\n",
        "    # is_motorway = None\n",
        "    # try:\n",
        "    #     is_motorway = topology_char.get('isMotorway', [{}])[0].get('value', None)\n",
        "    # except (IndexError, AttributeError, TypeError):\n",
        "    #     pass\n",
        "\n",
        "    # Start and end points of geometry\n",
        "    if geometry and geometry.coords:\n",
        "        startpt = list(geometry.coords)[0]\n",
        "        endpt = list(geometry.coords)[-1]\n",
        "    else:\n",
        "        startpt = endpt = None\n",
        "\n",
        "    processed_data.append({\n",
        "        \"id\": id_,\n",
        "        \"Pedestrian\": pedestrian,\n",
        "        \"Startpt\": startpt,\n",
        "        \"Endpt\": endpt,\n",
        "        \"isMotorway\": motorway\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame and save as CSV\n",
        "df = pd.DataFrame(processed_data)\n",
        "df.to_csv('output577_motorway.csv', index=False)\n",
        "\n",
        "print(\"CSV file created\")\n"
      ],
      "metadata": {
        "id": "ZvCIYOXWHkve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1120a6ec-087e-4fa6-ce8b-bf72200deea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make math csv\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "from ast import literal_eval\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv(\"output577_motorway.csv\")  # Replace with your path if needed\n",
        "\n",
        "# Convert Startpt and Endpt string values to tuples\n",
        "df[\"Startpt\"] = df[\"Startpt\"].apply(literal_eval)\n",
        "df[\"Endpt\"] = df[\"Endpt\"].apply(literal_eval)\n",
        "\n",
        "# Define the point to test against (longitude, latitude)\n",
        "# test_point = (10.0, 53.5)  # <- Update this point as needed\n",
        "\n",
        "# Function to compute perpendicular distance and intersection coordinate\n",
        "def perpendicular_distance_and_intersection(p, a, b):\n",
        "    y0, x0 = p\n",
        "    y1, x1 = a\n",
        "    y2, x2 = b\n",
        "\n",
        "    AB = np.array([x2 - x1, y2 - y1])\n",
        "    AP = np.array([x0 - x1, y0 - y1])\n",
        "\n",
        "    ab_squared = np.dot(AB, AB)\n",
        "    if ab_squared == 0:\n",
        "        intersect = a  # Line segment is a point\n",
        "    else:\n",
        "        t = np.dot(AP, AB) / ab_squared\n",
        "        t = max(0, min(1, t))  # Clamp to segment\n",
        "        intersect = (float(x1 + t * AB[0]), float(y1 + t * AB[1]))\n",
        "\n",
        "    dist = np.linalg.norm(np.array(intersect) - np.array(p))\n",
        "    return dist, intersect\n",
        "\n",
        "for _, vio in validations_filtered.iterrows():\n",
        "  latitude = validations_filtered['geometry'].iloc[0].y\n",
        "  longitude = validations_filtered['geometry'].iloc[0].x\n",
        "\n",
        "  test_point = (latitude, longitude)\n",
        "  print(test_point)\n",
        "  # Apply function to each row\n",
        "  df[\"perpendicular_dist\"] = df.apply(\n",
        "      lambda row: perpendicular_distance_and_intersection(test_point, row[\"Startpt\"], row[\"Endpt\"])[0],\n",
        "      axis=1\n",
        "  )\n",
        "\n",
        "  df[\"intersect_cord\"] = df.apply(\n",
        "      lambda row: perpendicular_distance_and_intersection(test_point, row[\"Startpt\"], row[\"Endpt\"])[1],\n",
        "      axis=1\n",
        "  )\n",
        "\n",
        "# Save the updated CSV (optional)\n",
        "df.to_csv(\"output_with_distances.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "nJiYCqDyHp8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "252a4c63-de2e-439c-f398-672dc016027b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(53.51555, 10.0047)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_topology_id(error_message):\n",
        "    # Regular expression to match the topology urn\n",
        "    match = re.search(r\"urn:here::here:Topology:(\\d+)\", error_message)\n",
        "\n",
        "    if match:\n",
        "        return match.group(1)  # Return the topology ID (the part after \"urn:here::here:Topology:\")\n",
        "    else:\n",
        "        return None  # Return None if no match is found\n",
        "\n",
        "# Example usage\n",
        "# error_message = \"Motorway Sign urn:here::here:signs:1622369126135402107 at Lat 10.00470037883686 Lon 53.515550601801934 is associated to a Topology urn:here::here:Topology:89894481 that has a range for Pedestrian = TRUE within 20m distance.\"\n",
        "\n",
        "# topology_id = extract_topology_id(error_message)\n",
        "# print(topology_id)  # Should print '89894481'\n"
      ],
      "metadata": {
        "id": "rou0f1DQPUwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scenario 2\n",
        "# import numpy as np\n",
        "# for _, vio in validations_filtered.iterrows():\n",
        "#   latitude = vio['geometry'].y\n",
        "#   longitude = vio['geometry'].x\n",
        "#   bounds = calculate_tile_bounds(latitude, longitude)\n",
        "#   # print(latitude)\n",
        "#   # print(longitude)\n",
        "#   # print(bounds)\n",
        "#   temp_df = pd.DataFrame(columns = df.columns)\n",
        "#   # TODO\n",
        "#   # FOREACH SEGMENT\n",
        "#   for _, seg in df.iterrows():\n",
        "#     if (seg['intersect_cord'][0] < bounds['north'] and seg['intersect_cord'][0] > bounds['south'] and\n",
        "#         seg['intersect_cord'][1] > bounds['west'] and seg['intersect_cord'][1] < bounds['east']):\n",
        "#       temp_df = pd.concat([temp_df, pd.DataFrame([seg])], ignore_index=True)\n",
        "#     else:\n",
        "#       continue\n",
        "\n",
        "#     if temp_df.empty:\n",
        "#         print(\"No segments found in bounds.\")\n",
        "#         continue\n",
        "#     temp_df.sort_values(by='perpendicular_dist')\n",
        "#     flag = 0\n",
        "\n",
        "#     for _, row in temp_df.iterrows():\n",
        "#       if (row['isMotorway']):\n",
        "#         flag = 1\n",
        "#         top_id = extract_topology_id(validations_filtered['Error Message'])\n",
        "#         if (temp_df['id'] != top_id):\n",
        "#           print(f\"Feature ID {feature_id}: needs to be assigned to Topological Segment {top_id} ----- RESOLVED\")\n",
        "#         else:\n",
        "#           print(f\"Feature ID {feature_id}: already assigned to Topological Segment {top_id} ----- CHECKING SCENARIO 3\")\n",
        "#         break\n",
        "#     if (flag == 0):\n",
        "#       print(\"No Motorways found in this area - confirm for sign existence\")\n",
        "\n",
        "    # if intersection point is in bounds\n",
        "      # append segment to temp_df\n",
        "    # else\n",
        "      # continue\n",
        "  # sort temp_df by perpendicular distance\n",
        "  # set flag = 0\n",
        "  # FOREACH ROW IN TEMP_DF\n",
        "    # if (isMotorway == true):\n",
        "      # set flag = 1\n",
        "      # if (already assigned to sign):\n",
        "        # fallthrough to scenario 3 ---- CHECKING SCENARIO 3\n",
        "      # else\n",
        "        # change assignment to current row\n",
        "        # remove from validations_data_filtered ---- RESOLVED\n",
        "      # BREAK\n",
        "  # if flag == 0\n",
        "    # print no mways found in area\n",
        "\n"
      ],
      "metadata": {
        "id": "v8ru9UaHAero"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(validations_filtered.shape)\n",
        "if (validations_filtered.shape[0] > 0):\n",
        "  for i, vio in validations_filtered.iterrows():\n",
        "      latitude = vio['geometry'].y\n",
        "      longitude = vio['geometry'].x\n",
        "      bounds = calculate_tile_bounds(latitude, longitude)\n",
        "      print(bounds)\n",
        "\n",
        "      temp_df = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "      for _, seg in df.iterrows():\n",
        "          if (seg['intersect_cord'][0] < bounds['north'] and seg['intersect_cord'][0] > bounds['south'] and\n",
        "              seg['intersect_cord'][1] > bounds['west'] and seg['intersect_cord'][1] < bounds['east']):\n",
        "              temp_df = pd.concat([temp_df, pd.DataFrame([seg])], ignore_index=True)\n",
        "\n",
        "      if temp_df.empty:\n",
        "          print(\"No segments found in bounds.\")\n",
        "          continue\n",
        "\n",
        "      print(temp_df.shape[0])\n",
        "\n",
        "      temp_df = temp_df.sort_values(by='perpendicular_dist')\n",
        "      flag = 0\n",
        "\n",
        "      for _, row in temp_df.iterrows():\n",
        "          if row['isMotorway']:\n",
        "              flag = 1\n",
        "              top_id = extract_topology_id(vio['Error Message'])\n",
        "              feature_id = vio['Feature ID']\n",
        "              if row['id'] != top_id:\n",
        "                  print(f\"Feature ID {feature_id}: needs to be assigned to Topological Segment {top_id} ----- RESOLVED\")\n",
        "                  validations_filtered = validations_filtered.drop(i)\n",
        "              else:\n",
        "                  print(f\"Feature ID {feature_id}: already assigned to Topological Segment {top_id} ----- CHECKING SCENARIO 3\")\n",
        "              break\n",
        "\n",
        "      if flag == 0:\n",
        "          print(f\"Feature ID {vio['Feature ID']}: No Motorways found in this area - confirm for sign existence\")\n",
        "\n",
        "print(validations_filtered.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKN5tUakRwcl",
        "outputId": "98c8fe12-78a7-4531-d3be-6153a8d08b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 12)\n",
            "{'north': 53.5200500045, 'south': 53.511049995499995, 'east': np.float64(10.012268062047452), 'west': np.float64(9.997131937952547)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-119-ad77de928b12>:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  temp_df = pd.concat([temp_df, pd.DataFrame([seg])], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n",
            "Feature ID urn:here::here:signs:1622369126135402107: No Motorways found in this area - confirm for sign existence\n",
            "(1, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scenario 3\n",
        "print(validations_filtered.shape)\n",
        "if (validations_filtered.shape[0] > 0):\n",
        "  for i, vio in validations_filtered.iterrows():\n",
        "    latitude = vio['geometry'].y\n",
        "    longitude = vio['geometry'].x\n",
        "    bounds = calculate_tile_bounds(latitude, longitude)\n",
        "\n",
        "    probe_filtered = probe_data[(probe_data['latitude'] >= bounds['south']) & (probe_data['latitude'] <= bounds['north']) & (probe_data['longitude'] >= bounds['west']) & (probe_data['longitude'] <= bounds['east'])]\n",
        "    # print(probe_filtered)\n",
        "    if probe_filtered['speed'].mean() > 70:\n",
        "      print(f\"Feature ID {vio['Feature ID']}: Average speed is too high for pedestrians. Pedestrian Flag needs to be set to False. ---- RESOLVED\")\n",
        "      validations_filtered = validations_filtered.drop(i)\n",
        "\n",
        "print(validations_filtered.shape)\n"
      ],
      "metadata": {
        "id": "vJpK5w7ZDyxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fca177fe-8133-4980-9c69-880e3fe8678e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 12)\n",
            "(1, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scenario 4\n",
        "\n",
        "if (validations_filtered.shape[0] == 0):\n",
        "  print(\"All violations resolved\")\n",
        "else:\n",
        "  for i, vio in validations_filtered.iterrows():\n",
        "    print(f\"Feature ID {vio['Feature ID']}: Represents legitimate exception. ---- ALL CASES RESOLVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAdgwCKiVu03",
        "outputId": "b5e3deb7-e5fd-48db-f817-31cae23651b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature ID urn:here::here:signs:1622369126135402107: Represents legitimate exception. ---- ALL CASES RESOLVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bounds output checker\n",
        "\n",
        "import math\n",
        "\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    # Radius of the Earth in meters\n",
        "    R = 6371000\n",
        "\n",
        "    # Convert latitude and longitude from degrees to radians\n",
        "    lat1_rad = math.radians(lat1)\n",
        "    lon1_rad = math.radians(lon1)\n",
        "    lat2_rad = math.radians(lat2)\n",
        "    lon2_rad = math.radians(lon2)\n",
        "\n",
        "    # Haversine formula\n",
        "    dlat = lat2_rad - lat1_rad\n",
        "    dlon = lon2_rad - lon1_rad\n",
        "    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2\n",
        "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
        "\n",
        "    # Calculate distance\n",
        "    distance = R * c\n",
        "    return distance\n",
        "\n",
        "# Define the coordinates from your bounds\n",
        "north = 53.51573000018\n",
        "south = 53.515369999819995\n",
        "east = 10.005002722481898\n",
        "west = 10.004397277518102\n",
        "\n",
        "# Calculate distances between each pair of latitudes and longitudes\n",
        "distance_north_south = haversine(north, east, south, east)  # North-South distance\n",
        "distance_east_west = haversine(north, east, north, west)  # East-West distance\n",
        "\n",
        "print(f\"North-South distance: {distance_north_south} meters\")\n",
        "print(f\"East-West distance: {distance_east_west} meters\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdt5gAHABq02",
        "outputId": "4c38e484-06eb-46bd-88ea-d6056a259a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "North-South distance: 40.03021362283044 meters\n",
            "East-West distance: 40.030043572189854 meters\n"
          ]
        }
      ]
    }
  ]
}